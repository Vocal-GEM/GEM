# VocalGEM Test Suite

Comprehensive testing infrastructure for the VocalGEM voice training application.

## ğŸ“Š Current Status

### Frontend (Vitest)
- **Test Files:** 33 total
- **Test Cases:** 178 total (140 passing)
- **New Tests Added:** 7 files with 94 test cases
- **Coverage:** Tracked via `npm run test:coverage`

### Backend (Pytest)
- **Test Files:** 4 total
- **Test Cases:** 52 total
- **Code Coverage:** 28% (validators at 100%)
- **Framework:** pytest with pytest-flask, pytest-cov

## ğŸš€ Quick Start

### Running All Tests

**Frontend:**
```bash
npm test                    # Run all tests
npm run test:watch         # Watch mode
npm run test:coverage      # With coverage report
```

**Backend:**
```bash
cd backend
pytest                     # Run all tests
pytest --cov=app          # With coverage
pytest -v                 # Verbose output
```

### Running Specific Tests

**Frontend:**
```bash
# Single file
npm test -- src/components/ui/Login.test.jsx

# Pattern matching
npm test -- src/hooks/*.test.js

# Specific test
npm test -- -t "renders login form"
```

**Backend:**
```bash
# Single file
pytest tests/test_auth.py

# Specific class
pytest tests/test_auth.py::TestAuthEndpoints

# Specific test
pytest tests/test_auth.py::TestAuthEndpoints::test_login_success

# By marker
pytest -m unit              # Unit tests only
pytest -m integration       # Integration tests only
```

## ğŸ“ Test Organization

### Frontend Tests (`src/`)

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.test.jsx          âœ… 9 tests
â”‚   â”‚   â”œâ”€â”€ GlobalErrorBoundary.test.jsx    âœ… 13 tests
â”‚   â”‚   â”œâ”€â”€ Login.test.jsx                  âœ… 13 tests
â”‚   â”‚   â”œâ”€â”€ Signup.test.jsx                 âš ï¸  13 tests (needs label fixes)
â”‚   â”‚   â”œâ”€â”€ AudioLibrary.test.jsx           ğŸ“ Existing
â”‚   â”‚   â”œâ”€â”€ Breadcrumbs.test.jsx            ğŸ“ Existing
â”‚   â”‚   â””â”€â”€ [other component tests]
â”‚   â””â”€â”€ viz/
â”‚       â””â”€â”€ ProgressCharts.test.jsx         ğŸ“ Existing
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useAchievements.test.js             âœ… 11 tests (NEW)
â”‚   â”œâ”€â”€ useSpeechRecognition.test.js        âœ… 15 tests (NEW)
â”‚   â”œâ”€â”€ useFeedback.test.js                 âœ… 14 tests (NEW)
â”‚   â”œâ”€â”€ useCourseProgress.test.js           ğŸ“ Existing
â”‚   â””â”€â”€ useTTS.test.js                      ğŸ“ Existing
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ AnalyticsService.test.js            ğŸ“ Existing
â”‚   â”œâ”€â”€ IndexedDBManager.test.js            ğŸ“ Existing
â”‚   â””â”€â”€ SyncManager.test.js                 ğŸ“ Existing
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ coachEngine.test.js                 ğŸ“ Existing
â”‚   â”œâ”€â”€ cppAnalysis.test.js                 ğŸ“ Existing
â”‚   â”œâ”€â”€ lpcAnalysis.test.js                 ğŸ“ Existing
â”‚   â””â”€â”€ pitch.test.js                       ğŸ“ Existing
â””â”€â”€ context/
    â”œâ”€â”€ LanguageContext.test.jsx            ğŸ“ Existing
    â”œâ”€â”€ SettingsContext.test.js             ğŸ“ Existing
    â””â”€â”€ TourContext.test.jsx                ğŸ“ Existing
```

### Backend Tests (`backend/tests/`)

```
backend/tests/
â”œâ”€â”€ conftest.py                             âœ… Test fixtures
â”œâ”€â”€ test_auth.py                            âœ… 17 tests (23 validators passing)
â”œâ”€â”€ test_validators.py                      âœ… 24 tests (23/24 passing)
â””â”€â”€ test_models.py                          âœ… 11 tests (needs google-generativeai)
```

## ğŸ¯ Test Categories

### Frontend

**Component Tests:**
- Rendering and mount behavior
- User interactions (clicks, inputs)
- State management
- Error states
- Loading states
- Modal behavior

**Hook Tests:**
- State initialization
- State updates
- Side effects
- Dependency management
- Custom logic

**Service Tests:**
- API calls
- Data persistence
- Sync operations
- Error handling

**Utility Tests:**
- Pure function logic
- Algorithm correctness
- Edge cases

### Backend

**API Endpoint Tests:**
- Request validation
- Response formatting
- Authentication/Authorization
- Error responses
- Status codes

**Model Tests:**
- CRUD operations
- Relationships
- Validation
- Constraints

**Validator Tests:**
- Input sanitization
- XSS prevention
- Format validation
- Security checks

## ğŸ§ª Test Patterns

### Frontend Patterns

**Component Testing:**
```javascript
import { render, screen, fireEvent } from '@testing-library/react';
import { describe, it, expect, vi } from 'vitest';

describe('MyComponent', () => {
    it('renders with props', () => {
        render(<MyComponent title="Test" />);
        expect(screen.getByText('Test')).toBeInTheDocument();
    });

    it('handles user interaction', () => {
        const onClick = vi.fn();
        render(<MyComponent onClick={onClick} />);

        fireEvent.click(screen.getByRole('button'));
        expect(onClick).toHaveBeenCalled();
    });
});
```

**Hook Testing:**
```javascript
import { renderHook, act } from '@testing-library/react';

it('updates state', () => {
    const { result } = renderHook(() => useMyHook());

    act(() => {
        result.current.update('value');
    });

    expect(result.current.value).toBe('value');
});
```

### Backend Patterns

**API Testing:**
```python
def test_endpoint(client, sample_user):
    response = client.post('/api/endpoint', json={
        'data': 'value'
    })

    assert response.status_code == 200
    data = response.get_json()
    assert data['success'] is True
```

**Model Testing:**
```python
def test_model_creation(db):
    model = MyModel(field='value')
    db.session.add(model)
    db.session.commit()

    assert model.id is not None
    assert model.field == 'value'
```

## ğŸ”§ Configuration

### Frontend (`vitest.config.js`)
```javascript
{
  environment: 'jsdom',
  globals: true,
  setupFiles: ['./src/test/setup.js'],
  coverage: {
    provider: 'v8',
    reporter: ['text', 'html', 'lcov'],
    exclude: ['**/*.test.{js,jsx}', '**/test/**']
  }
}
```

### Backend (`backend/pytest.ini`)
```ini
[pytest]
testpaths = tests
python_files = test_*.py
markers =
    unit: Unit tests
    integration: Integration tests
    slow: Slow running tests
```

## ğŸ“ˆ Coverage Reports

### Viewing Coverage

**Frontend:**
```bash
npm run test:coverage
open coverage/index.html     # macOS
start coverage/index.html    # Windows
```

**Backend:**
```bash
cd backend
pytest --cov=app --cov-report=html
open htmlcov/index.html      # macOS
start htmlcov/index.html     # Windows
```

### Coverage Goals

| Area | Current | Target |
|------|---------|--------|
| Frontend - Error Boundaries | 100% | 100% âœ… |
| Frontend - Authentication | ~90% | 90% âœ… |
| Frontend - Hooks | 71% | 80% |
| Backend - Validators | 100% | 100% âœ… |
| Backend - Models | Tested | 90% |
| Backend - Routes | Partial | 80% |
| **Overall Backend** | **28%** | **70%** |

## ğŸ› Debugging Tests

### Frontend

**Failed test:**
```bash
npm test -- --reporter=verbose src/path/to/test.jsx
```

**Single test:**
```bash
npm test -- -t "test name"
```

**Debug in browser:**
```bash
npm run test:ui
```

### Backend

**Verbose output:**
```bash
pytest -vv tests/test_file.py
```

**Show print statements:**
```bash
pytest -s tests/test_file.py
```

**Stop on first failure:**
```bash
pytest -x tests/
```

**Drop into debugger:**
```bash
pytest --pdb tests/test_file.py
```

## ğŸš¦ CI/CD Integration

Tests run automatically on:
- Push to `main` or `develop` branches
- Pull requests to `main` or `develop`

See `.github/workflows/tests.yml` for configuration.

**Status:** [![Tests](https://github.com/USER/REPO/actions/workflows/tests.yml/badge.svg)](https://github.com/USER/REPO/actions/workflows/tests.yml)

## ğŸ“š Resources

### Documentation
- **Main Guide:** [TESTING_GUIDE.md](../TESTING_GUIDE.md)
- **CI/CD Setup:** [CI_CD_SETUP.md](../CI_CD_SETUP.md)
- **Summary:** [TEST_IMPLEMENTATION_SUMMARY.md](../TEST_IMPLEMENTATION_SUMMARY.md)

### External Resources
- [Vitest Documentation](https://vitest.dev/)
- [Testing Library](https://testing-library.com/)
- [Pytest Documentation](https://docs.pytest.org/)
- [pytest-flask](https://pytest-flask.readthedocs.io/)

## ğŸ¤ Contributing

### Writing New Tests

1. **Match existing patterns:** Look at similar tests
2. **Use descriptive names:** `test_creates_user_with_valid_data`
3. **Test one thing:** Each test should verify one behavior
4. **Clean up:** Use fixtures and cleanup functions
5. **Document:** Add docstrings for complex tests

### Before Committing

```bash
# Run all tests
npm test
cd backend && pytest

# Check coverage
npm run test:coverage
cd backend && pytest --cov=app

# Lint code
npm run lint
```

### Adding New Test Files

**Frontend:**
1. Create `*.test.jsx` next to component
2. Import testing utilities
3. Write tests following patterns above
4. Verify with `npm test`

**Backend:**
1. Create `test_*.py` in `backend/tests/`
2. Import fixtures from `conftest.py`
3. Use pytest markers (`@pytest.mark.unit`)
4. Verify with `pytest`

## ğŸ‰ Success Metrics

### Current Achievements
- âœ… 146 new test cases added
- âœ… Coverage reporting configured
- âœ… CI/CD pipeline established
- âœ… Testing documentation created
- âœ… Error boundaries fully tested
- âœ… Authentication flows tested
- âœ… Input validation at 100%

### Next Milestones
- ğŸ¯ AudioEngine testing (0% â†’ 80%)
- ğŸ¯ Core views testing (8% â†’ 70%)
- ğŸ¯ Services testing (21% â†’ 80%)
- ğŸ¯ Backend routes (partial â†’ 80%)
- ğŸ¯ Integration tests (0 â†’ 10+ scenarios)
- ğŸ¯ E2E tests (0 â†’ 5+ workflows)

---

**Last Updated:** December 1, 2025
**Maintained By:** Development Team
**Test Framework:** Vitest 4.0.14 (Frontend) | Pytest 8.0.0 (Backend)
